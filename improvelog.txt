Gmk0
NN Policy
 input 15*15*2
 conv1 3*3*2*16 SAME relu
 conv2 3*3*16*48 SAME relu
 conv3 3*3*48*96 SAME relu
 conv4 3*3*96*96 SAME relu
 conv5 3*3*96*96 SAME relu
 conv6 3*3*96*96 SAME relu
 conv7 3*3*96*96 SAME relu
 conv8 3*3*96*1 SAME relu
 fc1 reshape conv8 15*15
 y softmax fc1
Loss cross_enptroy
NN Value
 input 15*15*2
 conv1 3*3*2*16 SAME relu
 conv2 3*3*16*48 SAME relu
 conv3 3*3*48*96 SAME relu
 conv4 3*3*96*96 SAME relu
 conv5 3*3*96*96 SAME relu
 conv6 3*3*96*96 SAME relu
 conv7 3*3*96*96 SAME relu
 conv8 3*3*96*1 SAME relu
 fc1 reshape conv8 225 relu
 y matmul fc1
Loss avg_sqr

GameRecord
  int stepcount
  int[stepcount] move form 0 to 225
  int winner 0,1,2

GameTrainData
  int stepcount
  int[stepcount] move
  pos
    prob, move
  pos policy[stepcount][225]   sigma policy=1
  int winner for z
  
mini_batch
  int count
  GameTrainData[count]

12-30
  target: conv->res
  +bn, +dual 

1-22
  starting SL test
  problem: speed of mcts too slow

1-23
  SL test ok
  completed NN estimate
  generate data test
  optimized mcts selection, 2-3x speed up

1-24
  self dataset ok, but found a few problem
  add dirlect noise
  start iteration 0

1-25
  found small fault at iteration 0
  output of winner reversed(correct by retransdata)
  a small fault in SL data transform and a big fault in It0 data trans.(fixed)

1-26
  iteration 0 ok
  test shows decay_reward is important (decay=0.85)
  weight_0 vs random
w    41         9
b    44         6
85% PASS

1-27
  optimzed tree search, 3x speed up

1-28
  training I1, decay=0.88 le=0.05 step=16k
  weight_1 vs weight_0
w    29         21
b    32         18
61% PASS
  tringing I2, decay=0.88 le=0.05 step=16k

1-29
  weight_2 vs weight_1
w    33         17
b    32         18
65% PASS
  training I3, decay=0.88 le=0.05 step=16k
weight_3 vs weight_2
w    30         20
b    29         21
59% PASS
weight_3 vs weight_1
w    37         13
b    37         13
extra test ok
training I4, decay=0.88 le=0.05 step=16k
weight_4 vs weight_3
w    31         19
b    43         7
74% PASS
1-30
training I5, decay=0.88 le=0.05 step=16k
weight_5 vs weight_4
w    29         21
b    30         20
59% PASS
training I6, decay=0.89 le=0.05 step=16k
w    36         14
b    32         18
68% PASS
1-31
training I7, decay=0.89 le=0.05 step=16k
w    49         1
b    35         15
84% PASS
training I8, decay=0.89 le=0.05 step=16k
w    47         3
b    26         24
73% PASS
2-1
fpu frac changed to 1.3
training I9, decay=0.89 le=0.05 step=16k
w    36         14
b    26         24
62%PASS
training I10, decay=0.89 le=0.05 step=16k
w    45         5
b    15         35 
60%PASS
2-2
training I11, decay=0.89 le=0.05 step=16k
w    43         7
b    24         26
67%PASS
find huge bug in data_gathering, trying to fix it
(Iteration 1-11 will strongly effected)
bug fixed
training I12, decay=0.89 le=0.05 step=16k
w    43         7
b    41         9
84%PASS
  weight_12 vs  SL   test
w    14         36
b    14         36
good progress!
2-3
training I13, decay=0.9 le=0.05 step=16k
w    41         9
b    48         2
89%PASS
training I14, decay=0.9 le=0.05 step=16k
w    35         15
b    44         6
79%PASS
2-4
training I15, decay=0.92 le=0.05 step=16k
w    35         15
b    41         9
76%PASS
training I16, decay=0.93 le=0.05 step=16k
w    36         14
b    45         5
81%PASS
  weight_16 vs  SL   test
w    23         27
b    27         23
50% maybe overfitting
  weight_16_puct=0.8 vs weight_16_puct=1.6
w    26         24
b    37         13
  weight_16_puct=1.6 vs weight_16_puct=1.6
w    10         40
b    47         3
  weight_16_puct=1.2 vs weight_16_puct=1.6
w    12         38
b    36         14
  weight_16_puct=0.5 vs weight_16_puct=1.6
w    14         36
b    32         18
puct now set to 0.8
2-5
training I17, decay=0.94 le=0.05 step=16k
w    35         15
b    44         6
79%PASS
add random transform in training
training I18, decay=0.95 le=0.05 step=16k
w    21         29
b    26         24
47%
training I19, decay=0.95 le=0.05 step=16k
w    24         26
b    37         13
61%PASS