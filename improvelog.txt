Gmk0
NN Policy
 input 15*15*2
 conv1 3*3*2*16 SAME relu
 conv2 3*3*16*48 SAME relu
 conv3 3*3*48*96 SAME relu
 conv4 3*3*96*96 SAME relu
 conv5 3*3*96*96 SAME relu
 conv6 3*3*96*96 SAME relu
 conv7 3*3*96*96 SAME relu
 conv8 3*3*96*1 SAME relu
 fc1 reshape conv8 15*15
 y softmax fc1
Loss cross_enptroy
NN Value
 input 15*15*2
 conv1 3*3*2*16 SAME relu
 conv2 3*3*16*48 SAME relu
 conv3 3*3*48*96 SAME relu
 conv4 3*3*96*96 SAME relu
 conv5 3*3*96*96 SAME relu
 conv6 3*3*96*96 SAME relu
 conv7 3*3*96*96 SAME relu
 conv8 3*3*96*1 SAME relu
 fc1 reshape conv8 225 relu
 y matmul fc1
Loss avg_sqr

GameRecord
  int stepcount
  int[stepcount] move form 0 to 225
  int winner 0,1,2

GameTrainData
  int stepcount
  int[stepcount] move
  pos
    prob, move
  pos policy[stepcount][225]   sigma policy=1
  int winner for z
  
mini_batch
  int count
  GameTrainData[count]

12-30
  target: conv->res
  +bn, +dual 

1-22
  starting SL test
  problem: speed of mcts too slow

1-23
  SL test ok
  completed NN estimate
  generate data test
  optimized mcts selection, 2-3x speed up

1-24
  self dataset ok, but found a few problem
  add dirlect noise
  start iteration 0

1-25
  found small fault at iteration 0
  output of winner reversed(correct by retransdata)
  a small fault in SL data transform and a big fault in It0 data trans.(fixed)

1-26
  iteration 0 ok
  test shows decay_reward is important (=0.9)
  weight_0 vs random
w    41         9
b    44         6
85% PASS